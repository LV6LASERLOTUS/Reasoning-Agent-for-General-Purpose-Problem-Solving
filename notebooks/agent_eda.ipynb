{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a67fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Add agent.py to the sys search search path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a7f0e",
   "metadata": {},
   "source": [
    "### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5ec07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from each type of Inference time algorithm:\n",
      "Self refine: $\\boxed{25}$\n",
      "ReAct Answer: To solve the problem, we assume there are 100 students in the school. \n",
      "CoT Answer: 25\n"
     ]
    }
   ],
   "source": [
    "robotucus = Agent(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\", \"cse476\"),\n",
    "    api_base=os.getenv(\"API_BASE\", \"http://10.4.58.53:41701/v1\"),\n",
    "    model_name=os.getenv(\"MODEL_NAME\", \"bens_model\"),\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "QUESTION=r\"\"\"\n",
    "In a new school, $40$ percent of the students are freshmen, $30$ percent are sophomores, $20$ percent are juniors, and $10$ percent are seniors. All freshmen are required to take Latin, and $80$ percent of sophomores, $50$ percent of the juniors, and $20$ percent of the seniors elect to take Latin. The probability that a randomly chosen Latin student is a sophomore is $\\\\frac{m}{n}$ , where $m$ and $n$ are relatively prime positive integers. Find $m+n$ .\n",
    "\"\"\".strip()\n",
    "\n",
    "self_refine_answer=robotucus.self_refine(QUESTION,max_calls=20)\n",
    "react_answer = robotucus.react(QUESTION,max_calls=20)\n",
    "CoT_answer = robotucus.chain_of_thought(QUESTION,max_calls=20)\n",
    "\n",
    "print(\n",
    "    \"Answer from each type of Inference time algorithm:\"\n",
    "    f\"\\nSelf refine: {self_refine_answer}\"\n",
    "    f\"\\nReAct Answer: {react_answer}\"\n",
    "    f\"\\nCoT Answer: {CoT_answer}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71211cac",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dccaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH='./dataset/cse476_final_project_dev_data.json'\n",
    "with open(DATA_PATH,'r') as file:\n",
    "    json_file:list=json.load(file)\n",
    "    dataset:list=pd.DataFrame(json_file)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = (dataset['domain']\n",
    "           .value_counts()\n",
    "           .index.tolist())\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini dataset of 50 samples\n",
    "\n",
    "SAMPLE_SIZE=10\n",
    "RANDOM_STATE=42\n",
    "mini_dataset = pd.DataFrame()\n",
    "\n",
    "for domain in domains:\n",
    "    sample = (dataset.query(\"domain==@domain\")\n",
    "              .sample(n=SAMPLE_SIZE,random_state=RANDOM_STATE)\n",
    "              .reset_index())\n",
    "    \n",
    "    mini_dataset=pd.concat([mini_dataset,sample],ignore_index=True)\n",
    "\n",
    "print(f\"Mini Dataset size: {len(mini_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff497d65",
   "metadata": {},
   "source": [
    "### Inference Algorithm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "robotucus = Agent(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\", \"cse476\"),\n",
    "    api_base=os.getenv(\"API_BASE\", \"http://10.4.58.53:41701/v1\"),\n",
    "    model_name=os.getenv(\"MODEL_NAME\", \"bens_model\"),\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25079bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = mini_dataset[\"input\"]\n",
    "\n",
    "mini_dataset['CoT'] = [robotucus.chain_of_thought(question=question) for question in tqdm(questions)]\n",
    "mini_dataset['self_refine']= [robotucus.self_refine(question=question,max_calls=5) for question in tqdm(questions)]\n",
    "mini_dataset['react']= [robotucus.react(question=question) for question in tqdm(questions)]\n",
    "mini_dataset.to_csv(\"./dataset/inference_algo_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f42d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM=\"\"\"\n",
    "You are a strict grader. Your task is to evaluate if a student's response exactly matches the correct answer.  \n",
    "\n",
    "- If the student's response is identical to the correct answer, respond with: True  \n",
    "- If the student's response differs in any way, respond with: False  \n",
    "\n",
    "Example:  \n",
    "\n",
    "Question: What is the capital of France?  \n",
    "Correct Answer: Paris  \n",
    "Student: Paris  \n",
    "Response: True  \n",
    "\n",
    "Question: What is 40 + 2?  \n",
    "Correct Answer: 42  \n",
    "Student: 43  \n",
    "Response: False  \n",
    "\n",
    "Always respond with only True or False, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset=pd.read_csv(\"./dataset/inference_algo_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_scores, CoT_scores, self_refine_scores = [], [], []\n",
    "\n",
    "for _,row in tqdm(mini_dataset.iterrows()):\n",
    "    \n",
    "    question, answer = row['input'], row['output']\n",
    "    react, CoT, self_refine = row['react'], row['CoT'], row['self_refine']\n",
    "\n",
    "\n",
    "    user_prompt=f\"question:\\n{question}\\nCorrect Answer: {answer}\\nStudent: {react}\"\n",
    "\n",
    "    react_score = robotucus.call_model(user=user_prompt,system=SYSTEM)\n",
    "    if react_score['text']:\n",
    "        react_scores.append(react_score['text'])\n",
    "\n",
    "    user_prompt=f\"question:\\n{question}\\nCorrect Answer: {answer}\\nStudent: {CoT}\"\n",
    "    CoT_score = robotucus.call_model(user=user_prompt,system=SYSTEM)\n",
    "    if CoT_score['text']:\n",
    "        CoT_scores.append(CoT_score['text'])\n",
    "\n",
    "    user_prompt=f\"question:\\n{question}\\nCorrect Answer: {answer}\\nStudent: {self_refine}\"\n",
    "    self_refine_score = robotucus.call_model(user=user_prompt,system=SYSTEM)\n",
    "    if self_refine_score['text']:\n",
    "        self_refine_scores.append(self_refine_score['text'])\n",
    "\n",
    "\n",
    "mini_dataset['react_scores']=react_scores\n",
    "mini_dataset['CoT_scores']=CoT_scores\n",
    "mini_dataset['self_refine_scores']=self_refine_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mini_dataset['react_scores'].value_counts())\n",
    "print(mini_dataset['CoT_scores'].value_counts())\n",
    "print(mini_dataset['self_refine_scores'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f99a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset[['CoT']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9bace6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8391af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse476-reasoning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
